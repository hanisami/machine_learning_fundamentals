{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practical exercise, we will be building a Na√Øve Bayes model that classifies new article into 20 different categories.\n",
    "\n",
    "We are new to the concept of processing text, which fall under the category of Natural Language processing. For the sake of using the Naive Bayes classifier, we will be using a TF-IDF Tockenizer, to convert the text into vectors so it can be fed to the Naive Bayes classifier. We have a description of the TF-IDF Tockenizer later in this notebook.\n",
    "\n",
    "Your main task in this notebook is to use the proper type of the Naive Bayes classifier (from the three types we learned about) and perform the proper evaluation. The rest of the cells are already provided, all you need to do is fill the missing pieces specified as \\<write your code here\\>.\n",
    "\n",
    "\n",
    "The dataset is accessible using the below link. We will be using the one provided by the Scikit-Learn library, so no need to download it.\n",
    "\n",
    "https://www.kaggle.com/datasets/crawford/20-newsgroups/data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification with Naive Bayes Classifier\n",
    "\n",
    "Naive Bayes classifier is used for text classification and spam detection tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T11:12:28.900575Z",
     "iopub.status.busy": "2022-06-12T11:12:28.900222Z",
     "iopub.status.idle": "2022-06-12T11:12:28.947306Z",
     "shell.execute_reply": "2022-06-12T11:12:28.946599Z",
     "shell.execute_reply.started": "2022-06-12T11:12:28.900547Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Model/estimator\n",
    "# !!!!!! <write your code here>\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Plotting library\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will be using 20 newsgroup dataset for classification.\n",
    "\n",
    "As a first step, let's download 20 newsgroup dataset with fetch_20newsgroups API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T11:14:08.886281Z",
     "iopub.status.busy": "2022-06-12T11:14:08.885922Z",
     "iopub.status.idle": "2022-06-12T11:14:18.318021Z",
     "shell.execute_reply": "2022-06-12T11:14:18.317099Z",
     "shell.execute_reply.started": "2022-06-12T11:14:08.886252Z"
    }
   },
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T11:14:18.372278Z",
     "iopub.status.busy": "2022-06-12T11:14:18.371857Z",
     "iopub.status.idle": "2022-06-12T11:14:18.379146Z",
     "shell.execute_reply": "2022-06-12T11:14:18.378375Z",
     "shell.execute_reply.started": "2022-06-12T11:14:18.372251Z"
    }
   },
   "outputs": [],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **20 categories** in the dataset. For simplicity, we will select 4 of these categories and download training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T11:16:59.654692Z",
     "iopub.status.busy": "2022-06-12T11:16:59.652839Z",
     "iopub.status.idle": "2022-06-12T11:17:00.375404Z",
     "shell.execute_reply": "2022-06-12T11:17:00.37445Z",
     "shell.execute_reply.started": "2022-06-12T11:16:59.654618Z"
    }
   },
   "outputs": [],
   "source": [
    "categories = ['talk.religion.misc', 'soc.religion.christian',\n",
    "             'sci.space', 'comp.graphics']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T11:17:32.720922Z",
     "iopub.status.busy": "2022-06-12T11:17:32.720505Z",
     "iopub.status.idle": "2022-06-12T11:17:32.726277Z",
     "shell.execute_reply": "2022-06-12T11:17:32.72534Z",
     "shell.execute_reply.started": "2022-06-12T11:17:32.720872Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's look at a sample training document.\n",
    "print(train.data[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing and modelling\n",
    "\n",
    "`Tfidfvectorizer` is one such API that converts text input into a vector of numerical values.\n",
    "\n",
    "- We will use `TfidfVectorizer` as a preprocessing step to obtain feature vector corresponding to the text document.\n",
    "- You can read more about `TfidfVectorizer` if you are interested in Natural Language Processing by accessing the following blog: https://medium.com/@cmukesh8688/tf-idf-vectorizer-scikit-learn-dbc0244a911a\n",
    "- The documentation of `TfidfVectorizer` is accessible of the Scikit-Learn website: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T11:21:18.19971Z",
     "iopub.status.busy": "2022-06-12T11:21:18.19919Z",
     "iopub.status.idle": "2022-06-12T11:21:18.204957Z",
     "shell.execute_reply": "2022-06-12T11:21:18.204289Z",
     "shell.execute_reply.started": "2022-06-12T11:21:18.19967Z"
    }
   },
   "outputs": [],
   "source": [
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you would have to create and train the Naive Bayes model. Make sure to select the proper one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T11:21:48.175704Z",
     "iopub.status.busy": "2022-06-12T11:21:48.174861Z",
     "iopub.status.idle": "2022-06-12T11:21:48.775838Z",
     "shell.execute_reply": "2022-06-12T11:21:48.77496Z",
     "shell.execute_reply.started": "2022-06-12T11:21:48.175664Z"
    }
   },
   "outputs": [],
   "source": [
    "# !!!!!! <write your code here>\n",
    "# !!!!!! <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first predict the labels for the test set and then calculate the confusion matrix for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T11:26:31.324499Z",
     "iopub.status.busy": "2022-06-12T11:26:31.324089Z",
     "iopub.status.idle": "2022-06-12T11:26:31.987061Z",
     "shell.execute_reply": "2022-06-12T11:26:31.986202Z",
     "shell.execute_reply.started": "2022-06-12T11:26:31.324468Z"
    }
   },
   "outputs": [],
   "source": [
    "# !!!!!! <write your code here>\n",
    "# !!!!!! <write your code here>\n",
    "# !!!!!! <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a tool to classify statements into one of these four classes.\n",
    "> Make use of `predict` function on the model. But before, you need to use the tf-idf tokenizer to transform the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T11:30:18.590291Z",
     "iopub.status.busy": "2022-06-12T11:30:18.589861Z",
     "iopub.status.idle": "2022-06-12T11:30:18.595561Z",
     "shell.execute_reply": "2022-06-12T11:30:18.594681Z",
     "shell.execute_reply.started": "2022-06-12T11:30:18.590255Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_category(s, train=train, model=model):\n",
    "    # !!!!!! <write your code here>\n",
    "    # !!!!!! <write your code here>\n",
    "    return train.target_names[pred[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!! <write your code here>\n",
    "# !!!!!! <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do some test on new samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T11:30:36.613114Z",
     "iopub.status.busy": "2022-06-12T11:30:36.612687Z",
     "iopub.status.idle": "2022-06-12T11:30:36.620736Z",
     "shell.execute_reply": "2022-06-12T11:30:36.620045Z",
     "shell.execute_reply.started": "2022-06-12T11:30:36.613078Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_category('sending a payload to the ISS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T11:30:58.905638Z",
     "iopub.status.busy": "2022-06-12T11:30:58.904855Z",
     "iopub.status.idle": "2022-06-12T11:30:58.914336Z",
     "shell.execute_reply": "2022-06-12T11:30:58.913218Z",
     "shell.execute_reply.started": "2022-06-12T11:30:58.90559Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_category('discussing islam vs atheism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T11:31:20.570102Z",
     "iopub.status.busy": "2022-06-12T11:31:20.569709Z",
     "iopub.status.idle": "2022-06-12T11:31:20.579025Z",
     "shell.execute_reply": "2022-06-12T11:31:20.577882Z",
     "shell.execute_reply.started": "2022-06-12T11:31:20.570071Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_category('determining the screen resolution')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30197,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
