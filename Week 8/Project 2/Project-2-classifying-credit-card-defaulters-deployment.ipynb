{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e6f7ff; padding: 20px; border-radius: 10px; text-align: center; border: 1px solid #b3e0ff;\">\n",
    "    <h1 style=\"font-size: 2.5em; margin-bottom: 10px; color: #005580;\">Project 2</h1>\n",
    "    <h2 style=\"font-size: 2em; font-weight: normal; color: #007acc;\">(Write Here: FIRSTNAME LASTNAME)</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "<div style=\"background-color: #f9f9f9; padding: 20px; border-radius: 8px; border: 1px solid #ddd; margin-bottom: 20px;\">\n",
    "    <h2 style=\"color: #333;\">About the Dataset</h2>\n",
    "    <p style=\"font-size: 16px; color: #555;\">\n",
    "        This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #f9f9f9; padding: 20px; border-radius: 8px; border: 1px solid #ddd; margin-bottom: 20px;\">\n",
    "    <h2 style=\"color: #333;\">Features</h2>\n",
    "    <p style=\"font-size: 16px; color: #555;\">There are 25 features:</p>\n",
    "    <ul style=\"font-size: 16px; color: #555; line-height: 1.6;\">\n",
    "        <li><strong>ID:</strong> ID of each client</li>\n",
    "        <li><strong>LIMIT_BAL:</strong> Amount of given credit in NT dollars (includes individual and family/supplementary credit)</li>\n",
    "        <li><strong>SEX:</strong> Gender (1=male, 2=female)</li>\n",
    "        <li><strong>EDUCATION:</strong> (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)</li>\n",
    "        <li><strong>MARRIAGE:</strong> Marital status (1=married, 2=single, 3=others)</li>\n",
    "        <li><strong>AGE:</strong> Age in years</li>\n",
    "        <li><strong>PAY_0:</strong> Repayment status in September 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)</li>\n",
    "        <li><strong>PAY_2:</strong> Repayment status in August 2005 (scale same as above)</li>\n",
    "        <li><strong>PAY_3:</strong> Repayment status in July 2005 (scale same as above)</li>\n",
    "        <li><strong>PAY_4:</strong> Repayment status in June 2005 (scale same as above)</li>\n",
    "        <li><strong>PAY_5:</strong> Repayment status in May 2005 (scale same as above)</li>\n",
    "        <li><strong>PAY_6:</strong> Repayment status in April 2005 (scale same as above)</li>\n",
    "        <li><strong>BILL_AMT1:</strong> Amount of bill statement in September 2005 (NT dollar)</li>\n",
    "        <li><strong>BILL_AMT2:</strong> Amount of bill statement in August 2005 (NT dollar)</li>\n",
    "        <li><strong>BILL_AMT3:</strong> Amount of bill statement in July 2005 (NT dollar)</li>\n",
    "        <li><strong>BILL_AMT4:</strong> Amount of bill statement in June 2005 (NT dollar)</li>\n",
    "        <li><strong>BILL_AMT5:</strong> Amount of bill statement in May 2005 (NT dollar)</li>\n",
    "        <li><strong>BILL_AMT6:</strong> Amount of bill statement in April 2005 (NT dollar)</li>\n",
    "        <li><strong>PAY_AMT1:</strong> Amount of previous payment in September 2005 (NT dollar)</li>\n",
    "        <li><strong>PAY_AMT2:</strong> Amount of previous payment in August 2005 (NT dollar)</li>\n",
    "        <li><strong>PAY_AMT3:</strong> Amount of previous payment in July 2005 (NT dollar)</li>\n",
    "        <li><strong>PAY_AMT4:</strong> Amount of previous payment in June 2005 (NT dollar)</li>\n",
    "        <li><strong>PAY_AMT5:</strong> Amount of previous payment in May 2005 (NT dollar)</li>\n",
    "        <li><strong>PAY_AMT6:</strong> Amount of previous payment in April 2005 (NT dollar)</li>\n",
    "        <li><strong>default.payment.next.month:</strong> Default payment (1=yes, 0=no)</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #f9f9f9; padding: 20px; border-radius: 8px; border: 1px solid #ddd;\">\n",
    "    <h2 style=\"color: #333;\">Overview</h2>\n",
    "    <p style=\"font-size: 16px; color: #555;\">\n",
    "        You task in this project is to perform all the steps required in the machine learning pipeline to obtain a propoer prediction model of the credit card payment defaulters, including: data cleaning, data analysis, data visualization, and training and evaluation of several machine learning algorithms.\n",
    "    </p >\n",
    "    <p style=\"font-size: 16px; color: #555;\">\n",
    "        We are directing you with the headers and tasks you have to implement to complete this project.\n",
    "        This notebook consists of the following parts:\n",
    "    </p>\n",
    "    <ol style=\"font-size: 16px; color: #555; line-height: 1.6;\">\n",
    "        <li>Exploratory Data Analysis</li>\n",
    "        <li>Data Cleaning and Further Exploration</li>\n",
    "        <li>Building a Base Model</li>\n",
    "        <li>Feature Engineering</li>\n",
    "        <li>Building ML Models Using Various Algorithms and Comparing Them</li>\n",
    "        <li>Conclusion</li>\n",
    "    </ol>\n",
    "    <p style=\"font-size: 20px; color: #011;\">\n",
    "        NOTE: Please don't use ChatGPT or any sort of AI to complete your project. We are aware of how these models generate the answers and this would definitley affect your final grade.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2bbbd9be-d5d6-4607-9786-072d67b87303",
    "_kg_hide-output": true,
    "_uuid": "5ba24adc75c0d29f38ff44a0718bb2d8034ba584",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns',None)\n",
    "sns.set(style=\"darkgrid\", palette=\"pastel\", color_codes=True)\n",
    "sns.set_context('paper')\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "# from plotly.subplots import make_subplots\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFE,SelectFromModel\n",
    "from sklearn.model_selection import KFold,GridSearchCV,RandomizedSearchCV,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix,f1_score,roc_auc_score,roc_curve,accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import plotly.figure_factory as ff \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "373de127-2f57-439e-b3fb-febc86cf821c",
    "_uuid": "866eacd59f720b77731a2e041471b5999ac4906c"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"./UCI_Credit_Card.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c855e309-85e8-426f-ab80-050b16db868c",
    "_uuid": "391f4b0edb2c804475fd6e35cd738025095f00b5"
   },
   "source": [
    "#### Let's see if the data has any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Well it looks like there are no missing values which skips one of the main parts of pre-processing i.e. missing value imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's check dtypes of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f6bc9ca2-b40e-4346-838a-922e110d5f20",
    "_uuid": "bf10536e7bcca34164565abf554bffe558ed0d5f"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Statistical description of the features: [3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Numerical features:\n",
    "- Select the numerical features from the dataset based on the info displayed above\n",
    "- Print the statistical summary from the numerical features (hind: call describe function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Categorical features:\n",
    "- Select the categorical features from the dataset based on the info displayed above\n",
    "- Print the statistical summary from the categorical features (hind: call describe function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f1796586-38ba-4b68-990e-33323cbc2856",
    "_uuid": "7ff6b6f89760fafc327b3852e03333fb547ff784",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Rename:\n",
    "   - the target column to \"default\"\n",
    "   - payment status \"PAY_0\" \"PAY_1\" to make it continous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Anaysis: [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Categorical features:\n",
    "- In this part of the project, your task is to analyse the categorical features\n",
    "- You are required to plot some charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Marriage: \n",
    "- Extract the different categories of the marriage  (0, 1, 2, and 3) and their value counts (hind: use value_counts)\n",
    "- Plot a bar graph to show the distribution of the different marriage categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here for the plot>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What do you think about the obtained plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<write your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Education:\n",
    "- Extract the different categories of the education  (0, 1, 2, 3, 4, 5 and 6) and their value counts (hind: use value_counts)\n",
    "- In a seperate dataframe, extract the value count from the dataset of the education\n",
    "- Name every index as follows:\n",
    "    - 0 --> University\n",
    "    - 1 --> Graduate School\n",
    "    - 2 --> High school\n",
    "    - 3 --> Unknown 1\n",
    "    - 4 --> Others\n",
    "    - 5 --> Unknown 2\n",
    "    - 6 --> Unknown 3\n",
    "- Plot a bar graph to show the distribution of the different education categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What do you think about the obtained plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<write your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Sex\n",
    "- Extract the different categories of the sex (0, and 1) and their value counts (hint: use value_counts)\n",
    "- Store the dataframe in a separate variable\n",
    "- Rename the following:\n",
    "    - 0 to Male\n",
    "    - 1 to Female\n",
    "- Plot a bar graph to show the distribution of the different sex categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What do you think about the obtained plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<write your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Numerical variables:\n",
    "In this section of the project, you need to plot histograms for the different numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Bill amount:\n",
    "- Select the six BILL features and store them in a separate dataframe\n",
    "- Draw SIX different histograms for each of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What do you think about the obtained plot? Any transformation might be required?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<write your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Previous payment\n",
    "- Select the six PAY Aount ('PAY_AMT1 --> PAY_AMT6') features and store them in a separate dataframe\n",
    "- Draw SIX different histograms for each of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What do you think about the obtained plot? Any transformation might be required?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<write your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Previous payment status:\n",
    "- Select the six previous PAY status Aount ('PAY1 --> PAY6') features and store them in a separate dataframe\n",
    "- Draw SIX different histograms for each of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What do you think about the obtained plot? Any transformation might be required?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<write your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) Age:\n",
    "- Plot a histogram of the age feature ('AGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What do you think about the obtained plot? Any transformation might be required?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<write your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) Amount given in credit:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram of the age feature ('LIMIT_BAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What do you think about the obtained plot? Any transformation might be required?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<write your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6) Target column (Default):\n",
    "- Extract the different categories of the default column and their value counts (hint: use value_counts)\n",
    "- Store the dataframe in a separate variable\n",
    "- Create a bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What do you think about the obtained plot? Any transformation might be required?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<write your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation:\n",
    "- Create a correlation plot for the different features in the original dataframe (hint: use sns.heatmap for the plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What do you think about the obtained plot? Any transformation might be required?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<write your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data cleaning and further exploration: [3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you might have seen in the previous section of the project, there are some undocumented elements in some features, which means we don't really know what they mean\n",
    "\n",
    "Therefore, we will start by cleaning them up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Replace the values 0, 5, and 6 by the value 4 (resembling the 'Other' category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Replace the value 0 in MARRIAGE by 3 (resembling the 'Other' category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Replace -1 and -2 by 0 in all the PAY_1 --> PAY_6\n",
    "\"-1\" is paid duly, but there are \"-2\" and \"0\" labels in payment status variable. So let's combine them and put everything as \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Baseline model: [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create and evaluate a baseline model using KFold cross validation\n",
    "\n",
    "1) Split the data into 70\\% training and 30\\% testing. Select the default as label\n",
    "\n",
    "2) Create a Logistic Regression model with random_state=0. This model should be created on the resulting dataframe from the preprocessing without any fine tuning\n",
    "\n",
    "3) Apply K-fold cross validation with cv=5 and train the model\n",
    "\n",
    "4) evaluate the model by computing:\n",
    "   - The accuracy\n",
    "   - The confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What do you think about this accuracy? Does it need improvement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<write your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9472ee05-4b8b-4176-b321-30c87b7a2a03",
    "_uuid": "1d0706cc0446eb357066d310e142a550bf3197c7"
   },
   "source": [
    "# 5. Feature Engineering [3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) One hot encode all categorical features\n",
    "- Convert the dtypes of 'SEX', 'MARRIAGE', and 'EDUCATION' to the dtype 'object'\n",
    "- apply one hot encoding (hint: use the get_dummies function provided by pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Split the dataset between 70\\% training and 30\\% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Confirm class imbalance in the labels of the dataset\n",
    "\n",
    "- Print the distribution of the labels in the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There's a lot of imbalance in the sample. So there are many ways to resampling!\n",
    "\n",
    "### Resampling involves creating a new transformed version of the training dataset in which the selected examples have a different class distribution. This is a simple and effective strategy for imbalanced classification problems.\n",
    "\n",
    "### The simplest strategy is to choose examples for the transformed dataset randomly, called random resampling. There are two main approaches to random resampling for imbalanced classification; they are oversampling and undersampling.\n",
    "\n",
    "#### A) Random Oversampling: Randomly duplicate examples in the minority class.\n",
    "#### B) Random Undersampling: Randomly delete examples in the majority class.\n",
    "#### C) SMOTE: Synthetic Minority Oversampling Technique\n",
    "\n",
    "#### Let's look at them, one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Random Oversampling: [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random oversampling involves randomly duplicating examples from the minority class and adding them to the training dataset.\n",
    "\n",
    "#### Examples from the training dataset are selected randomly with replacement. This means that examples from the minority class can be chosen and added to the new “more balanced” training dataset multiple times; they are selected from the original training dataset, added to the new training dataset, and then returned or “replaced” in the original dataset, allowing them to be selected again.\n",
    "\n",
    "#### To implement random oversampling, you need to use the resample function from the sklearn.utils package\n",
    "Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html\n",
    "\n",
    "- Implement random oversampling\n",
    "- Store the resulting dataframe in a new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4ada9173-97ec-4f78-8fbb-6929e9ed50bb",
    "_uuid": "1cd3116618a42760cc4436cb36f4d3701e359d72"
   },
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Random Undersampling: [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random undersampling involves randomly selecting examples from the majority class to delete from the training dataset.\n",
    "\n",
    "#### This has the effect of reducing the number of examples in the majority class in the transformed version of the training dataset. This process can be repeated until the desired class distribution is achieved, such as an equal number of examples for each class.\n",
    "\n",
    "#### This approach may be more suitable for those datasets where there is a class imbalance although a sufficient number of examples in the minority class, such a useful model can be fit.\n",
    "\n",
    "#### To implement random undersampling, you need to use the resample function from the sklearn.utils package\n",
    "\n",
    "Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html\n",
    "\n",
    "- Implement random undersamping\n",
    "- Store the resulting dataframe in a new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "054f2635-e062-45c6-9072-ec21c26bd861",
    "_uuid": "85d677968a1dfba6642ef2090addc38ebb53c063"
   },
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) SMOTE: Synthetic Minority Oversampling Technique [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The upsample has the disadvantage of increasing the likelihood of overfitting since it replicates the minority class event. It usually outperform the downsampling. The downsample can discard potentially useful information and the sample can be biased, but it helps improving the run time\n",
    "\n",
    "#### SMOTE works by selecting examples that are close in the feature space, drawing a line between the examples in the feature space and drawing a new sample at a point along that line. To create a syntetic sample I want to use the SMOTE algorithm, which is an oversampling method which creates synthetic (fake) samples from the minority class instead of creating copies. It selects 2 or more similar instances and perturb them one at a time by random amount. This techniques should avoid overfitting problems but it risks adding noise to the model\n",
    "\n",
    "#### To implement SMOTE, you need to use the SMOTE function from the imblearn package\n",
    "Documentation: https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html\n",
    "- Implement SMOTE samling\n",
    "- Store the resulting dataframe in a new variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Models Building, Training, and Evaluation [9 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At this point, we have 4 sets of training data:\n",
    "\n",
    "#### 1) The normal train data with unbalance\n",
    "#### 2) Train data with oversampling\n",
    "#### 3) Train data with undersampling\n",
    "#### 4) Train data with SMOTE algorithm\n",
    "\n",
    "#### The evaluation will be based on K fold cross validation through the accuracy score\n",
    "\n",
    "#### First let's define a function which evaluates the model with train and test score and also performs a K-fold cross validation on the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(algo, Xtrain,ytrain,Xtest,ytest):\n",
    "    # algo is the machine learning algorithm\n",
    "    from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "    # WITHOUT KFOLDS CROSS VALIDATION\n",
    "    # <write your code: fit the training data to the model>\n",
    "    # <write your code: following training, perform prediction on the train data>\n",
    "\n",
    "    # <write your code: print the training accuracy score>\n",
    "    \n",
    "    # <write your code: perform prediction on the test data>\n",
    "    # <write your code: print the testing accuracy score>\n",
    "    # <write your code: print the classification report (hint: use classification_report())>\n",
    "    \n",
    "    \n",
    "    # WITH KFOLDS CROSS VALIDATION\n",
    "    # Define the kfold cross validation with the following\n",
    "    # parameters: n_splits=5, shuffle=True, random_state=42\n",
    "    kf = KFold(n_splits = 5,shuffle = True,random_state = 42)\n",
    "    score=[]\n",
    "    for train_idx,test_idx in kf.split(Xtrain,ytrain):\n",
    "        xtrain_k,xtest_k = Xtrain.iloc[train_idx,:],Xtrain.iloc[test_idx,:]\n",
    "        ytrain_k,ytest_k = ytrain.iloc[train_idx],ytrain.iloc[test_idx]\n",
    "        # <write your code: fit the train data of the fold to the model>\n",
    "        # <write your code: perform prediction on the test data>\n",
    "        # <write your code: obtain the accuracy score>\n",
    "        score.append(acc)\n",
    "    print('K-Fold scores: %0.03f' % (np.mean(score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your task is to use the following supervised machine learning algorithms with the 4 different datasets (normal, downsampling, upsampling, and smote) and also with hyperparameter tuning the models\n",
    "\n",
    "#### i) Logistic Regression\n",
    "#### ii) Naive Bayes\n",
    "#### iii) K-Nearest Neighbours\n",
    "#### iv) Decision Tree\n",
    "#### v) Random Forest\n",
    "#### vi) Support Vectore Machine\n",
    "\n",
    "### We will be providing the code for the Logistic Regression model with some missing pieces. You can use it to inspire for writing the rest of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Logistic Regression: [6 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's first find out the best parameters for all the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# You might need to change the name of the following dataframes (normal and sampled) \n",
    "# depending on whatever you named them before\n",
    "\n",
    "xtrain_data = [X_train,df_upsampled.drop('default',axis = 1),df_downsampled.drop('default',axis = 1),X_SMOTE]\n",
    "ytrain_data = [y_train,df_upsampled['default'],df_downsampled['default'],y_SMOTE]\n",
    "name = ['Normal Sampling' , 'Over Sampling' , 'Under Sampling' , 'SMOTE']\n",
    "\n",
    "for i,j,k in zip(xtrain_data,ytrain_data,name):\n",
    "    print('Data is ',k)\n",
    "    best_log = []\n",
    "    # Setup the hyperparameter grid, (not scaled data)\n",
    "    # <write your code: define the parameters to use the RandomizedSearchCV>\n",
    "    # Instantiate a logistic regression classifier\n",
    "    logreg = LogisticRegression()\n",
    "    # Instantiate the RandomizedSearchCV object\n",
    "    logreg_cv = RandomizedSearchCV(logreg, param_grid ,scoring = 'roc_auc', cv=5, random_state=0)\n",
    "    # Fit it to the data\n",
    "    # <write your code: fit the training data to the model>\n",
    "    best_log.append(logreg_cv.best_params_)\n",
    "    # Print the tuned parameters and score\n",
    "    print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
    "    print(\"_\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation of logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Update the param log based on the best values obtained for each dataframe here. Here is an example.\n",
    "param_log =[{'C': 3.727593720314938},{'C': 11787686.347935867},{'C': 0.05179474679231213},{'C': 31.622776601683793}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_data = [X_train,df_upsampled.drop('default',axis = 1),df_downsampled.drop('default',axis = 1),X_SMOTE]\n",
    "ytrain_data = [y_train,df_upsampled['default'],df_downsampled['default'],y_SMOTE]\n",
    "name = ['Normal Sampling' , 'Over Sampling' , 'Under Sampling' , 'SMOTE']\n",
    "index = [0,1,2,3]\n",
    "\n",
    "for i,j,k,l in zip(xtrain_data,ytrain_data,name,index):\n",
    "    print('Data is ',k,' And with hyper parameter ',param_log[l])\n",
    "    model_eval(LogisticRegression(**param_log[l],random_state= 42), i,j,X_test,y_test)\n",
    "    print(\"_\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Naive bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) K-Nearest Neighbours: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vi) Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <write your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclude on the best model, the best parameter, and the best sampling approach used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<write your answer here\\>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
